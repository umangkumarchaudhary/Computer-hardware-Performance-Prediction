{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d3553a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5    69\n",
      "6     5\n",
      "7     5\n",
      "8     0\n",
      "9     0\n",
      "dtype: int64\n",
      "       0     1      2      3     4      5    6    7\n",
      "0    125   256   6000  256.0  16.0  128.0  198  199\n",
      "1     29  8000  32000   32.0   8.0   32.0  269  253\n",
      "2     29  8000  32000   32.0   8.0   32.0  220  253\n",
      "3     29  8000  32000   32.0   8.0   32.0  172  253\n",
      "4     29  8000  16000   32.0   8.0   16.0  132  132\n",
      "..   ...   ...    ...    ...   ...    ...  ...  ...\n",
      "204  124  1000   8000    NaN   1.0    8.0   42   37\n",
      "205   98  1000   8000   32.0   2.0    8.0   46   50\n",
      "206  125  2000   8000    NaN   2.0   14.0   52   41\n",
      "207  480   512   8000   32.0   NaN    NaN   67   47\n",
      "208  480  1000   4000    NaN   NaN    NaN   45   25\n",
      "\n",
      "[209 rows x 8 columns]\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "dtype: int64\n",
      "A\n",
      "            0         1         2         3         4         5         6  \\\n",
      "0    0.072825  0.006012  0.092843  1.000000  0.294118  0.725714  0.167832   \n",
      "1    0.008092  0.248497  0.499499  0.121569  0.137255  0.177143  0.229895   \n",
      "2    0.008092  0.248497  0.499499  0.121569  0.137255  0.177143  0.187063   \n",
      "3    0.008092  0.248497  0.499499  0.121569  0.137255  0.177143  0.145105   \n",
      "4    0.008092  0.248497  0.249249  0.121569  0.137255  0.085714  0.110140   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "204  0.072151  0.029309  0.124124  0.143641  0.000000  0.040000  0.031469   \n",
      "205  0.054619  0.029309  0.124124  0.121569  0.019608  0.040000  0.034965   \n",
      "206  0.072825  0.060621  0.124124  0.143641  0.019608  0.074286  0.040210   \n",
      "207  0.312205  0.014028  0.124124  0.121569  0.074779  0.101232  0.053322   \n",
      "208  0.312205  0.029309  0.061562  0.143641  0.074779  0.101232  0.034091   \n",
      "\n",
      "            7  \n",
      "0    0.150450  \n",
      "1    0.194603  \n",
      "2    0.194603  \n",
      "3    0.194603  \n",
      "4    0.095666  \n",
      "..        ...  \n",
      "204  0.017989  \n",
      "205  0.028618  \n",
      "206  0.021259  \n",
      "207  0.026165  \n",
      "208  0.008177  \n",
      "\n",
      "[209 rows x 8 columns]\n",
      "(209,) (209, 7)\n",
      "(146, 7) (63, 7) (146,) (63,)\n",
      "KNN Results:\n",
      "MSE for training:  0.002554754494475733\n",
      "MSE for testing:  0.0014268423883808498\n",
      "R2 score for training:  0.8913381628995283\n",
      "R2 score for testing:  0.8640645328276492\n",
      "\n",
      "SVM Results:\n",
      "MSE for training:  0.0028014157039236176\n",
      "MSE for testing:  0.003801839212641823\n",
      "R2 score for training:  0.880846876860894\n",
      "R2 score for testing:  0.6377982644102076\n",
      "\n",
      "Linear Regression Results:\n",
      "MSE for training:  0.0011182035868411116\n",
      "MSE for testing:  0.001679204527185257\n",
      "R2 score for training:  0.9524392436685285\n",
      "R2 score for testing:  0.8400219577581496\n",
      "\n",
      "Decision Tree Results:\n",
      "MSE for training:  6.73189548740368e-05\n",
      "MSE for testing:  0.0016510720728378078\n",
      "R2 score for training:  0.9971367106608036\n",
      "R2 score for testing:  0.8427021404858053\n",
      "\n",
      "Logistic Regression Results:\n",
      "Accuracy for training:  0.8561643835616438\n",
      "Accuracy for testing:  0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read the data into a pandas dataframe\n",
    "df = pd.read_csv(\"cpudata.data\", delimiter='\\t', header=None, na_values=\"0\")\n",
    "print(df.isna().sum())\n",
    "df=df.drop([0, 1], axis=1)\n",
    "df.columns = range(df.shape[1])\n",
    "print(df)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "df_i=pd.DataFrame(SimpleImputer(strategy=\"mean\").fit_transform(df))\n",
    "print(df_i.isna().sum())\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler ##MinMaxScaler is for Normalisation\n",
    "df_i=pd.DataFrame(MinMaxScaler().fit_transform(df_i))\n",
    "print(\"A\")\n",
    "print(df_i)\n",
    "\n",
    "target=df_i[6]\n",
    "data=df_i.drop(columns=[6])\n",
    "print(target.shape, data.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(data, target, test_size=0.3)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# KNN regression algorithm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(x_train, y_train)\n",
    "knn_train_pred=knn_model.predict(x_train)\n",
    "knn_test_pred=knn_model.predict(x_test)\n",
    "\n",
    "# SVM regression algorithm\n",
    "from sklearn.svm import SVR\n",
    "svm_model=SVR(kernel='linear')\n",
    "svm_model.fit(x_train, y_train)\n",
    "svm_train_pred=svm_model.predict(x_train)\n",
    "svm_test_pred=svm_model.predict(x_test)\n",
    "\n",
    "# Decision Tree regression algorithm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(x_train, y_train)\n",
    "dt_train_pred=dt_model.predict(x_train)\n",
    "dt_test_pred=dt_model.predict(x_test)\n",
    "\n",
    "# Linear regression algorithm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "model=LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "train_pred=model.predict(x_train)\n",
    "test_pred=model.predict(x_test)\n",
    "\n",
    "# Evaluate performance of all three models\n",
    "print(\"KNN Results:\")\n",
    "print(\"MSE for training: \", mean_squared_error(y_train, knn_train_pred))\n",
    "print(\"MSE for testing: \", mean_squared_error(y_test, knn_test_pred))\n",
    "print(\"R2 score for training: \", r2_score(y_train, knn_train_pred))\n",
    "print(\"R2 score for testing: \", r2_score(y_test, knn_test_pred))\n",
    "\n",
    "print(\"\\nSVM Results:\")\n",
    "print(\"MSE for training: \", mean_squared_error(y_train, svm_train_pred))\n",
    "print(\"MSE for testing: \", mean_squared_error(y_test, svm_test_pred))\n",
    "print(\"R2 score for training: \", r2_score(y_train, svm_train_pred))\n",
    "print(\"R2 score for testing: \", r2_score(y_test, svm_test_pred))\n",
    "\n",
    "print(\"\\nLinear Regression Results:\")\n",
    "print(\"MSE for training: \", mean_squared_error(y_train, train_pred))\n",
    "print(\"MSE for testing: \", mean_squared_error(y_test, test_pred))\n",
    "print(\"R2 score for training: \", r2_score(y_train, train_pred))\n",
    "print(\"R2 score for testing: \", r2_score(y_test, test_pred))\n",
    "\n",
    "# Evaluate performance of decision tree model\n",
    "print(\"\\nDecision Tree Results:\")\n",
    "print(\"MSE for training: \", mean_squared_error(y_train, dt_train_pred))\n",
    "print(\"MSE for testing: \", mean_squared_error(y_test, dt_test_pred))\n",
    "print(\"R2 score for training: \", r2_score(y_train, dt_train_pred))\n",
    "print(\"R2 score for testing: \", r2_score(y_test, dt_test_pred))\n",
    "\n",
    "# Logistic regression algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# convert the target variable to binary values for logistic regression\n",
    "target_bin = np.where(target > target.median(), 1, 0)\n",
    "\n",
    "# split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target_bin, test_size=0.3)\n",
    "\n",
    "# fit the logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the training and testing sets\n",
    "train_pred = logistic_model.predict(x_train)\n",
    "test_pred = logistic_model.predict(x_test)\n",
    "\n",
    "# evaluate the performance of the model\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(\"Accuracy for training: \", logistic_model.score(x_train, y_train))\n",
    "print(\"Accuracy for testing: \", logistic_model.score(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d6761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
